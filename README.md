# 開発者向けドキュメント

## はじめに

本ドキュメントは、EEGIRL_Controllerの開発者向けドキュメントです。
EEGIRL_Controllerのソースコードに関しては、自由に改変及び再配布が可能です。
配布の際は、本開発者陣に連絡をしていただけると嬉しいです。見に行きます。
なお、EEGIRL_Controllerの後継開発者はVN3ライセンス規約に従う必要があり、
開発者が本ソースコードを使用した際に伴う損失は、本開発者陣は一切責任を負いません。
上記を承知の上、ご利用ください。

## 目次

- [開発者向けドキュメント](#開発者向けドキュメント)
  - [はじめに](#はじめに)
  - [目次](#目次)
  - [1. 付属アプリ「EEGIRL\_Controller」のシステム構成](#1-付属アプリeegirl_controllerのシステム構成)
    - [1.1 動作環境](#11-動作環境)
    - [1.2 対応機種](#12-対応機種)
    - [1.3 対応サービス](#13-対応サービス)
    - [1.4 論理構成](#14-論理構成)
      - [1.4.1 操作層](#141-操作層)
      - [1.4.2 接続層](#142-接続層)
      - [1.4.3 解析層](#143-解析層)
      - [1.4.4 通信層](#144-通信層)
    - [1.5 BCIの処理概要](#15-bciの処理概要)
      - [1.5.1 脳波の種類](#151-脳波の種類)
      - [1.5.2 SSVEPの測定](#152-ssvepの測定)
      - [1.5.3 SSVEPの解析](#153-ssvepの解析)
      - [1.5.4 前処理](#154-前処理)
      - [1.5.5 信号処理](#155-信号処理)
      - [1.5.6 周波数検知](#156-周波数検知)
    - [1.6 通信仕様](#16-通信仕様)
      - [1.6.1 VRChat OSC通信用の変数](#161-vrchat-osc通信用の変数)
      - [1.6.2 VRChat MIDI通信用の変数](#162-vrchat-midi通信用の変数)
  - [2. ビルド方法](#2-ビルド方法)
    - [2.1 前提](#21-前提)
    - [2.2 Dockerコンテナでパスを取得](#22-dockerコンテナでパスを取得)
    - [2.3 specファイルを編集する](#23-specファイルを編集する)
    - [2.4 exeファイル作成](#24-exeファイル作成)

## 1. 付属アプリ「EEGIRL_Controller」のシステム構成

### 1.1 動作環境

本アプリの動作環境はVRChatとの接続を前提としている都合上、Windows10/11のみとしています。

### 1.2 対応機種

本アプリの外部入力装置として対応している機種は次の通りです。

- OpenBCI Cyton Board

がんばって対応機種を増やします。

### 1.3 対応サービス

本アプリから制御データを転送する対象は次の通りです。

- VRChat

また、外部出力装置はVRChatの対応機種に依存しています。

### 1.4 論理構成

以下は本アプリを機能別に説明するための論理的な構成を示したものです。
また、実際のソースコードでは通信層が解析層に組み込まれています。

1. 操作層：GUIでデータ処理命令を実行
2. 接続層：脳波測定装置からデータを入力
3. 解析層：PCで測定データを解析して制御信号に変換
4. 通信層：制御信号を外部に出力

#### 1.4.1 操作層

操作層では、アプリケーションを構成するGUI要素の表示と各機能との接続を行っています。
この層を担っているソースコードは次の通りです。

- `control-gui.py`

ここで使用しているライブラリは次の通りです。

- `PySimpleGUI`

`PySimpleGUI`はPythonでGUIアプリを作成するためのライブラリで、
`tkinter`というPythonの標準GUIライブラリを簡単に使えるようにしたものです。
コードをシンプルに書けるため応用のしやすさや保守の観点から採用しました。

今回はコードを簡潔にするため実装から外していますが
今後はnumpyとthreadを用いたグラフのリアルタイム描画をこの層に実装する予定です。

#### 1.4.2 接続層

接続層では、脳波測定装置と無線通信するためのUSBドングルが接続されているシリアルポートへのアクセスをしています。
この層を担っているソースコードは次の通りです。

- `connect-port.py`

ここで使用しているライブラリは次の通りです。

- `serial`

`serial`は、Pythonでシリアルポートにアクセスするためのモジュールです。
ここでは、シリアル通信では接続できるポートをリストアップし、接続先のポートをGUIで選択して通信テストを行います。
Windowsでポートの詳細情報を確認する場合は、デバイスマネージャーなどをご利用してください。

#### 1.4.3 解析層

解析層では、脳波測定装置からシリアル通信で測定データを取得し、
内部で解析してから、VRChat用のアバターやワールドのギミック向けに制御信号に変換しています。
この層を担っているソースコードは次の通りです。

- `process-ssvep.py`

ここで使用しているライブラリは次の通りです。

- `brainflow`
- `mne`
- `mne-realtime`

`brainflow`では脳波測定装置からポート経由でシリアル通信をし、測定データの取得を行います。
`mne`では測定データを解析するための事前定義を行います。
`mne-realtime`ではエポックをリアルタイムに処理をし、誘発反応の検知データを取得します。
その後、検知データから単純な制御信号に変換します。

今回は誘発反応の検知データの対象としてSSVEPを用いるため、
事前定義の内、検知情報として外部からの光刺激の周波数を用いています。
SSVEPの測定と解析については後述します。

なお、脳波測定データの直接送信を行うようなアルゴリズムの配布を行う予定はありません。
理由として生データをそのまま送信してしまうと通信の盗聴等で外部からデータ収集出来てしまうセキュリティリスクがあり、
欧州のGDPRやAI規制法の高リスク群に抵触する可能性があるためです。
そのため、プライバシーポリシーで述べたようにローカル環境内で逆解析の困難な単純な制御用パルス信号に変換することにしました。

#### 1.4.4 通信層

通信層では、制御信号をLocal Network経由で外部アプリケーションに送信します。
この層を担っているソースコードは次の通りです。

- `process-ssvep.py`

ここで使用しているライブラリは次の通りです。

- `pythonosc`
- `mido`

制御信号の送信には今回、OSC通信とMIDI通信を利用しています。
これは今回の送信先の外部アプリケーション対象としてVRChatを用いており
VRChat SDKの仕様上、受信可能な通信プロトコルが、アバターの場合はOSC通信、ワールドの場合はMIDI通信に限定されるためです。

MIDI通信の受信先となるワールドはまだ制作中ですので、しばらくお待ち下さい。
完成次第、配布サイト及びSNSでお知らせいたします。

### 1.5 BCIの処理概要

#### 1.5.1 脳波の種類

他にもありますが、非侵襲型BCIにおける脳波測定の種類[^1]として知られているものとして以下のようなものがあります。

> - SSVEP (Steady State Visual Evoked Potential: 定常状態視覚誘発電位)
> - ERP (Event Related Potential: 事象関連電位)
> - MI (Motor Imagery: 運動想起)

事象関連電位や運動関連応答など様々な脳波がある中で、
今回SSVEPを採用した理由は、脳波を発生させることが他の脳波と比較して容易であること、
VR環境ではSSVEPはユーザーに直接視覚情報を与えることが可能であることが挙げられます。
今後は、SSVEP以外の脳波を用いたBCIシステムの開発も行っていきたいと考えています。

[^1]: [東 広志, 中西 正樹, 田中 聡久, 脳波処理とブレイン・コンピュータ・インタフェース ,コロナ社, 2022/10/20](https://www.coronasha.co.jp/np/isbn/9784339014044/)

#### 1.5.2 SSVEPの測定

SSVEP（Steady State Visual Evoked Potential）とは、
定常状態視覚誘発電位の略で、定常的な視覚刺激を与えることで大脳皮質視覚野に生じる脳波のことです。
視覚刺激の繰り返し周波数と同じ周波数の脳波が検出されるという特徴があります。
本制作物と同様の視覚情報処理の研究[^4]や、BCIなどの応用分野で活用されています。

SSVEPの測定方法は、以下の通りです。
まず、ユーザーには本製品に内蔵された電極を頭部に装着してもらいます。
次に、ユーザーには画面上に表示された複数の視覚刺激のうち、一つを注視してもらいます。
各視覚刺激はそれぞれ異なる周波数で点滅しており、ユーザーが注視した刺激の周波数がSSVEPとして脳波に現れます。
脳波をリアルタイムで解析し、SSVEPの周波数を特定します。
そして、その周波数に対応するコマンドや操作を実行します。

[^4]: [定常状態視覚誘発電位を用いたブレインコンピュータインタフェースの性能向上と測定システムに関する研究, 松井 大輔, 靏 浩二, 大分工業高等専門学校第52号, 2015](https://www.jstage.jst.go.jp/article/oitactkiyou/52/0/52_KJ00010026947/_pdf/-char/ja)

#### 1.5.3 SSVEPの解析

測定データの解析の工程は論文によって様々ありますが
本アプリでは前処理、信号処理、周波数検知の順に行いました。
以下は具体的なアルゴリズムと手法について述べたものです。

1. 前処理
    - Common Average Reference (CAR)による平均参照化
    - ハイパスフィルターによる低周波ノイズの除去
    - ノッチフィルターによる交流電源ノイズの除去
2. 信号処理
    - 窓関数によるウェルチ法によるパワースペクトル密度 (PSD) の計算
    - 予め定めた周波数帯域のPSDを合計してSSVEPパワーを算出
    - ノイズパワーの算出
3. 周波数検知
    - SNRの算出
    - 予め定めた閾値を超えるSSVEPパワーを持つ周波数を検出
    - 検出した周波数に対応した制御値をMIDIまたはOSC信号の出力
    - 計算されたSNR値のMIDIまたはOSC信号の出力

#### 1.5.4 前処理

今回前処理では、CARによる平均参照化やノイズ除去等の処理を行っています。本来はアーティファクトの除去を想定しICA (独立成分分析) の実装も必要だと思われますが、ICAは計算量が多くリアルタイム処理には向いていないため前処理には採用しませんでした。

#### 1.5.5 信号処理

FFT (高速フーリエ変換) の関数は用いていませんが、これはウェルチ法自体が窓関数とFFTの組み合わせでPSDを計算しているため間接的には使用しています。またFFTを直接行うよりもウェルチ法の方が信号の非定常性や不等間隔サンプリングなどの問題に対処できる柔軟性と精度を持つため、ウェルチ法を用いています。

#### 1.5.6 周波数検知

検知にはSIR[^3] (Spectrum Intensity Ratio) を用いる予定でしたが、SIRの実装には時間がかかりそうだったため、今回は閾値を超えるSSVEPパワーを持つ周波数を検出するアルゴリズムを実装しました。今後は検出精度を向上させるためSIRを用いた検出アルゴリズムの実装や提示する光刺激の改良などを行っていく予定です。

[^3]: [Spectrum Intensity Ratio and Thresholding Based SSVEP Detection, Akitoshi Itai, Arao Funase, 2013 Volume 51 Issue Supplement Pages R-213](https://www.jstage.jst.go.jp/article/jsmbe/51/Supplement/51_R-213/_pdf/-char/ja)

### 1.6 通信仕様

#### 1.6.1 VRChat OSC通信用の変数

VRChat SDKでは、OSC通信を用いてパラメータの送受信が可能です。
ただし、VRChat独自の規格に従っているため、送受信を行う場合は様々な制約[^2]があります。
以下は本制作物でOSC通信用に定義した EEGIRL ThirdArm の駆動用変数を示したものです。

1. **EEGIRL_Grab**: 手を握る動作を制御する値
    - `変数型：bool型 (1bit)`
    - `範囲：0 / 1`

2. **EEGIRL_Direction**: 腕をどの方向に動かすかを制御する値
    - `変数型：int型 (8bit)`
    - `範囲：0 ~ 128`

3. **EEGIRL_Multiplication**: 腕をどれだけ動かすかを制御する値
    - `変数型：int型 (8bit)`
    - `範囲：0 ~ 30`

[^2]: [VRChatのExpression Parameters (Animator Parameters) の仕様](https://docs.vrchat.com/docs/animator-parameters)

#### 1.6.2 VRChat MIDI通信用の変数

ワールド作成次第、整備予定

## 2. ビルド方法

### 2.1 前提

本ドキュメントにおけるビルド環境は
VRChatの動作に合わせるため、以下としています。

- DockerDesktop & WSL2 ( Windows 10 / 11 )

開発環境でビルドするとexeファイルが肥大化し
不必要な読み込みで動作が重くなるため
上記のような仮想環境内でビルドを行う方式にしました。

### 2.2 Dockerコンテナでパスを取得

この操作は、Windows環境でDocker Desktop.exeを使用する際に必要になります。
Windows（ホスト環境）に既にモジュールが`pip install`されていると、
Dockerのコンテナ環境でなくホスト環境のパスが参照されることがあります。
これを避けるために予めコンテナ環境内でのモジュールのパスを設定します。
なお、この手順はWindows環境でのみを想定した操作になりますのでご注意ください。

例として、下記ではmneライブラリのコンテナ環境内のパスを取得しています。

まず、Dockerコンテナを実行し、Pythonインタプリタを起動します。

```shell
docker run --rm -v "${PWD}:/src/" -it apemill/pyinstaller-windows /bin/bash
```

コンテナ内で、下記のコマンドを実行します。
下記のコマンドは、コンテナ内で`js_and_css`ディレクトリのパスを取得するものです。

```shell
find / -name "js_and_css" 2>/dev/null
```

出力されたパスをコピーし、以下で`main.spec`ファイルを編集します。
なお、複数のパスが出力された場合は、以下で示す方法で`mne`ライブラリのパスを取得するコマンドを実行してください。

```shell
pip install mne
```

```python
import os
import mne

mne_js_and_css_path = os.path.join(os.path.dirname(mne.__file__), 'report', 'js_and_css')
print(mne_js_and_css_path)
```

### 2.3 specファイルを用意する

本フォルダ内には、下記の記述を実施済みのmain.specというファイルを梱包しています。
これは、PyInstallerを用いてexeファイルを作成する際に必要なファイルです。

以下では、何らかの機能実装にあたりライブラリ参照に関連するランタイムエラーが発生した際に、ファイルを修正する必要がある場合の手順を示します。
.specファイルを開き、a = Analysis()の部分を探します。
datasという引数が見つかるまでスクロールし、以下のように変更します。

```shell
a = Analysis(['main.py'],
             pathex=['\\path\\to\\your\\project'],
             binaries=[],
             datas=[
                 ('path\to\mne\report\js_and_css', 'mne\\report\\js_and_css')
                 ...
             ],
             ...
             )
```

ここで、前述のコードで取得した各パスについて
`'path\to\mne\report\js_and_css'`を、`print(mne_js_and_css_path)`に
置き換えてください。
他の項目についても、同様の方法でパスを取得し、記述してください。

### 2.4 exeファイル作成

修正した.specファイルを使用して以下のビルド用コマンドから、アプリケーションをビルドし直します。
以下ではビルドコマンドを説明するために、コマンドを分割して説明しています。

1. ボリュームをマウントしてコンテナを実行:
```shell
docker run --rm -v "${PWD}:/src/" -it apemill/pyinstaller-windows /bin/bash
```
   このコマンドは実行するとコンテナのシェルにアクセスできます。
   アクセス後は以下のコマンドをコンテナ内で実行してください。

2. ホイールファイルのインストール:
   コンテナのシェル内で次のコマンドを実行します。
```shell
pip install /src/python_rtmidi-1.5.5-cp311-cp311-win_amd64.whl
```

3. 依存関係のインストール:
```shell
pip install -r /src/requirements.txt
```

4. PyInstallerを使用してexeを生成:
```shell
pyinstaller /src/main.spec --clean
```

5. 生成されたexeファイルを移動:
```shell
mv dist/main.exe /src/main.exe
```

6. 不要なファイルやディレクトリの削除:
```shell
rm -rf __pycache__/ build/ dist/
```
